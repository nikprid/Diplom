{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b572b989-c352-4304-9618-d214df50cb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA+keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a8f86dc-cc46-4c6f-8b77-b1b83b687857",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13174f57-d9e9-4ef6-9599-ca21b9424978",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('keystroke/userdata/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "479d4943-7819-419f-8a92-57ea5e12e3e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2981"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.sample(frac=1).reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23fdca26-1f47-4f67-994f-bff120b163f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+]: keystroke/userdata/processed_data\\Alexander_processed_data.csv\n",
      "[+]: keystroke/userdata/processed_data\\Alex_processed_data.csv\n",
      "[+]: keystroke/userdata/processed_data\\Artem_processed_data.csv\n",
      "[+]: keystroke/userdata/processed_data\\DDD_processed_data.csv\n",
      "[+]: keystroke/userdata/processed_data\\Imya_processed_data.csv\n",
      "[+]: keystroke/userdata/processed_data\\nevova_processed_data.csv\n",
      "[+]: keystroke/userdata/processed_data\\Nikita_processed_data.csv\n",
      "[+]: keystroke/userdata/processed_data\\Sasha_processed_data.csv\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "data = pd.DataFrame(columns=['keycode','HD','PPD','RPD', 'RRD', 'user'])\n",
    "for file in glob.glob(\"keystroke/userdata/processed_data/*_processed_data.csv\"):\n",
    "    print('[+]:', file)\n",
    "    tmp = pd.read_csv(file)\n",
    "    data = pd.concat([data, tmp], ignore_index=True)\n",
    "\n",
    "data.to_csv('keystroke/userdata/data.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bb33040-d443-4906-bdeb-6382e0d374ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=pd.read_csv('server/keystroke/Nikita_test_logs.csv')\n",
    "df = pd.DataFrame(columns=['keycode','HD','PPD','RPD', 'RRD', 'user'])\n",
    "\n",
    "user = test_data.user[0]\n",
    "event_len = len(test_data)\n",
    "\n",
    "for i in range(event_len-3):\n",
    "    if str(test_data.iloc[i].event) == 'Down':\n",
    "        finalData = {}\n",
    "        cur_key_press_time = test_data.iloc[i].time\n",
    "        cur_key_release_time =  test_data[(test_data.keycode==test_data.iloc[i].keycode)&(test_data.event=='Up')&(test_data.time>test_data.iloc[i].time)].iloc[0].time\n",
    "        next_key_press_time = test_data[(test_data.event=='Down')&(test_data.time>test_data.iloc[i].time)].iloc[0].time\n",
    "        next_key_keycode = test_data[(test_data.event=='Down')&(test_data.time>test_data.iloc[i].time)].iloc[0].keycode\n",
    "        next_key_release_time =  test_data[(test_data.keycode==next_key_keycode)&(test_data.event=='Up')&(test_data.time>next_key_press_time)].iloc[0].time\n",
    "        finalData['keycode'] = test_data.iloc[i].keycode\n",
    "        finalData['HD'] = cur_key_release_time-cur_key_press_time\n",
    "        finalData['PPD'] = next_key_press_time-cur_key_press_time\n",
    "        finalData['RPD'] = next_key_press_time-cur_key_release_time\n",
    "        finalData['RRD'] = next_key_release_time-cur_key_release_time\n",
    "        finalData['user'] = user\n",
    "        df = df.append(finalData,ignore_index=True)\n",
    "\n",
    "df.keycode = df.keycode.apply(int).apply(str) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "71da5e9f-9997-41ab-bddb-d63c1adc4438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nu = 0.33, gamma = 0.33, max = 0.2589285714285714\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.svm import OneClassSVM\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "nu = np.arange(0.01, 1, 0.01)\n",
    "gamma = np.arange(0.01, 1, 0.0025)\n",
    "max = 0\n",
    "for n in nu:\n",
    "    for g in gamma:\n",
    "        dif_len_rate = 0\n",
    "        i = 0\n",
    "        for l in range(40, 60, 3):\n",
    "            n_scaler = preprocessing.Normalizer()\n",
    "            data = pd.read_csv('server/keystroke/userdata/processed_data/Nikita_processed_data.csv')[:l]\n",
    "            col_names = ['HD', 'PPD', 'RPD', 'RRD']\n",
    "            data_s = n_scaler.fit_transform(data[col_names])\n",
    "            data_s = pd.DataFrame(data_s, columns = col_names)\n",
    "            data_s['keycode']=data.keycode.astype('str')\n",
    "            clf = OneClassSVM(nu=n, kernel=\"rbf\", gamma=g)\n",
    "            #clf = SGDOneClassSVM(nu=0.5)\n",
    "            clf.fit(data_s)\n",
    "\n",
    "            Alex_data = pd.read_csv('server/keystroke/userdata/processed_data/Alex_processed_data.csv')[:20]\n",
    "            Alex_data_s = n_scaler.transform(Alex_data[col_names])\n",
    "            Alex_data_s = pd.DataFrame(Alex_data_s, columns = col_names)\n",
    "            Alex_data_s['keycode']=Alex_data.keycode.astype('str')\n",
    "            _, Alex_count =np.unique(clf.predict(Alex_data_s), return_counts=True)\n",
    "            #print(f'Probability of valid user (Alex_1): {Alex_count[1]/20}')\n",
    "\n",
    "            DDD_data = pd.read_csv('server/keystroke/userdata/processed_data/DDD_processed_data.csv')[:20]\n",
    "            DDD_data_s = n_scaler.transform(DDD_data[col_names])\n",
    "            DDD_data_s = pd.DataFrame(DDD_data_s, columns = col_names)\n",
    "            DDD_data_s['keycode']=DDD_data.keycode.astype('str')\n",
    "            _, DDD_count =np.unique(clf.predict(DDD_data_s), return_counts=True)\n",
    "            #print(f'Probability of valid user (Dmitry): {DDD_count[1]/20}')\n",
    "\n",
    "            Sasha_data = pd.read_csv('server/keystroke/userdata/processed_data/Sasha_processed_data.csv')[:20]\n",
    "            Sasha_data_s = n_scaler.transform(Sasha_data[col_names])\n",
    "            Sasha_data_s = pd.DataFrame(Sasha_data_s, columns = col_names)\n",
    "            Sasha_data_s['keycode']=Sasha_data.keycode.astype('str')\n",
    "            _, Sasha_count = np.unique(clf.predict(Sasha_data_s), return_counts=True)\n",
    "            #print(f'Probability of valid user (Alex_2): {Sasha_count[1]/20}')\n",
    "\n",
    "            Artem_data = pd.read_csv('server/keystroke/userdata/processed_data/Artem_processed_data.csv')[:20]\n",
    "            Artem_data_s = n_scaler.transform(Artem_data[col_names])\n",
    "            Artem_data_s = pd.DataFrame(Artem_data_s, columns = col_names)\n",
    "            Artem_data_s['keycode']=Artem_data.keycode.astype('str')\n",
    "            _, Artem_count = np.unique(clf.predict(Artem_data_s), return_counts=True)\n",
    "            #print(f'Probability of valid user (Artem): {Artem_count[1]/20}')\n",
    "\n",
    "            df_s = n_scaler.transform(df[col_names])\n",
    "            df_s = pd.DataFrame(df_s, columns = col_names)\n",
    "            df_s['keycode']=df.keycode.astype('str')\n",
    "            _, test_valid_counts = np.unique(clf.predict(df_s[:20]), return_counts=True)\n",
    "            #print(f'Probability of valid user (Nikita_test): {test_valid_counts[1]/20}')\n",
    "            _, test_valid_counts_2 = np.unique(clf.predict(df_s[20:40]), return_counts=True)\n",
    "            #print(f'Probability of valid user (Nikita_test_2): {test_valid_counts_2[1]/20}')\n",
    "            try:\n",
    "                false_rate = (Alex_count[1]+DDD_count[1]+Sasha_count[1]+Artem_count[1])/80\n",
    "                true_rate = (test_valid_counts[1]+test_valid_counts_2[1])/40\n",
    "                dif_len_rate+=(true_rate-false_rate)\n",
    "                i+=1\n",
    "            except:\n",
    "                pass\n",
    "        try:\n",
    "            mean_rate = dif_len_rate/i\n",
    "            if mean_rate>max:\n",
    "                max = mean_rate\n",
    "                max_n = n\n",
    "                max_g = n\n",
    "        except:\n",
    "            pass           \n",
    "            # if Alex_count[1]/20<0.5 and DDD_count[1]/20<0.5 and Sasha_count[1]/20<0.5 and Artem_count[1]/20<0.5 and test_valid_counts[1]/20>0.59 and test_valid_counts_2[1]/20>0.59:\n",
    "            #     print(f'nu = {n}, gamma = {g}')\n",
    "print(f'nu = {max_n}, gamma = {max_g}, max = {max}')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "fa1d002e-bcd2-4aec-b525-c6e05485541b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([-1,  1], dtype=int64), array([22,  3], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "col_names = ['HD', 'PPD', 'RPD', 'RRD']\n",
    "df_s = n_scaler.fit_transform(df[col_names])\n",
    "df_s = pd.DataFrame(df_s, columns = col_names)\n",
    "df_s['keycode']=df.keycode.astype('str')\n",
    "print(np.unique(clf.predict(df_s[:25]), return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "fbda9c91-2bb3-4c76-86f9-e2a0f80ff78b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(clf.predict(df_s[:20]), return_counts=True)[1][1]/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a855f93c-9c49-4dfc-872f-5bf3ba91827f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of valid user (Alex_1): 0.5\n",
      "Probability of valid user (Dmitry): 0.55\n",
      "Probability of valid user (Alex_2): 0.45\n",
      "Probability of valid user (Artem): 0.6\n",
      "Probability of valid user (Nikita_test): 0.85\n",
      "Probability of valid user (Nikita_test_2): 0.8\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.svm import OneClassSVM\n",
    "import numpy as np\n",
    "\n",
    "n_scaler = preprocessing.Normalizer()\n",
    "data = pd.read_csv('server/keystroke/userdata/processed_data/Nikita_processed_data.csv')[:49]\n",
    "col_names = ['HD', 'PPD', 'RPD', 'RRD']\n",
    "data_s = n_scaler.fit_transform(data[col_names])\n",
    "data_s = pd.DataFrame(data_s, columns = col_names)\n",
    "data_s['keycode']=data.keycode.astype('str')\n",
    "\n",
    "# nu = np.arange(0.01, 1, 0.01)\n",
    "# gamma = np.arange(0.01, 1, 0.01)\n",
    "# for n in nu:\n",
    "#     for g in gamma:\n",
    "clf = OneClassSVM(nu=0.04, kernel=\"rbf\", gamma=0.0275)\n",
    "#clf = SGDOneClassSVM(nu=0.5)\n",
    "clf.fit(data_s)\n",
    "\n",
    "Alex_data = pd.read_csv('server/keystroke/userdata/processed_data/Alex_processed_data.csv')[:20]\n",
    "Alex_data_s = n_scaler.transform(Alex_data[col_names])\n",
    "Alex_data_s = pd.DataFrame(Alex_data_s, columns = col_names)\n",
    "Alex_data_s['keycode']=Alex_data.keycode.astype('str')\n",
    "_, Alex_count =np.unique(clf.predict(Alex_data_s), return_counts=True)\n",
    "print(f'Probability of valid user (Alex_1): {Alex_count[1]/20}')\n",
    "\n",
    "DDD_data = pd.read_csv('server/keystroke/userdata/processed_data/DDD_processed_data.csv')[:20]\n",
    "DDD_data_s = n_scaler.transform(DDD_data[col_names])\n",
    "DDD_data_s = pd.DataFrame(DDD_data_s, columns = col_names)\n",
    "DDD_data_s['keycode']=DDD_data.keycode.astype('str')\n",
    "_, DDD_count =np.unique(clf.predict(DDD_data_s), return_counts=True)\n",
    "print(f'Probability of valid user (Dmitry): {DDD_count[1]/20}')\n",
    "\n",
    "Sasha_data = pd.read_csv('server/keystroke/userdata/processed_data/Sasha_processed_data.csv')[:20]\n",
    "Sasha_data_s = n_scaler.transform(Sasha_data[col_names])\n",
    "Sasha_data_s = pd.DataFrame(Sasha_data_s, columns = col_names)\n",
    "Sasha_data_s['keycode']=Sasha_data.keycode.astype('str')\n",
    "_, Sasha_count = np.unique(clf.predict(Sasha_data_s), return_counts=True)\n",
    "print(f'Probability of valid user (Alex_2): {Sasha_count[1]/20}')\n",
    "\n",
    "Artem_data = pd.read_csv('server/keystroke/userdata/processed_data/Artem_processed_data.csv')[:20]\n",
    "Artem_data_s = n_scaler.transform(Artem_data[col_names])\n",
    "Artem_data_s = pd.DataFrame(Artem_data_s, columns = col_names)\n",
    "Artem_data_s['keycode']=Artem_data.keycode.astype('str')\n",
    "_, Artem_count = np.unique(clf.predict(Artem_data_s), return_counts=True)\n",
    "print(f'Probability of valid user (Artem): {Artem_count[1]/20}')\n",
    "\n",
    "df_s = n_scaler.transform(df[col_names])\n",
    "df_s = pd.DataFrame(df_s, columns = col_names)\n",
    "df_s['keycode']=df.keycode.astype('str')\n",
    "_, test_valid_counts = np.unique(clf.predict(df_s[:20]), return_counts=True)\n",
    "print(f'Probability of valid user (Nikita_test): {test_valid_counts[1]/20}')\n",
    "_, test_valid_counts_2 = np.unique(clf.predict(df_s[20:40]), return_counts=True)\n",
    "print(f'Probability of valid user (Nikita_test_2): {test_valid_counts_2[1]/20}')\n",
    "        # if Alex_count[1]/20<0.5 and DDD_count[1]/20<0.5 and Sasha_count[1]/20<0.5 and Artem_count[1]/20<0.5 and test_valid_counts[1]/20>0.49 and test_valid_counts_2[1]/20>0.49:\n",
    "        #     print(f'nu = {n}, gamma = {g}')     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc3edf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f6b3db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
